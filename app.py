import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import plotly.graph_objects as go
from datetime import datetime, timedelta

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
st.set_page_config(page_title="Z88 Predator - Sovereign Hub", layout="wide", initial_sidebar_state="expanded")

# --- Ù…Ø­Ø±Ùƒ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Ù…Ø§Ù†Ø¹ Ø§Ù„Ø§Ù†Ù‡ÙŠØ§Ø±) ---
def load_and_fix_data(file):
    try:
        if file.name.endswith('.xlsx'):
            df = pd.read_excel(file)
        else:
            df = pd.read_csv(file, encoding='utf-8-sig')
        
        # ØªÙ†Ø¸ÙŠÙ Ø´Ø§Ù…Ù„ Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ù€ Duplicate Column Ø§Ù„Ù…Ø°ÙƒÙˆØ±Ø© ÙÙŠ Ø§Ù„Ù€ Logs
        df.columns = [str(c).strip() for c in df.columns]
        df = df.loc[:, ~df.columns.duplicated()]
        
        # ØªÙˆØ­ÙŠØ¯ Ù…Ø³Ù…ÙŠØ§Øª Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù„Ù…Ù„ÙÙƒ Ø§Ù„Ø®Ø§Øµ Ù„Ø¶Ù…Ø§Ù† Ø¹Ù…Ù„ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª
        mapping = {
            'Ø§Ù„Ø±Ù…Ø²': 'Ø§Ù„Ø±Ù…Ø²', 'Ø¥ØºÙ„Ø§Ù‚': 'Ø¥ØºÙ„Ø§Ù‚', 'Ø§Ù„Ø³ÙŠÙˆÙ„Ø©': 'Ø§Ù„Ø³ÙŠÙˆÙ„Ø©', 
            'Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒÙ‡': 'Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒÙ‡', 'Ø§Ù„Ø§Ø±ØªÙƒØ§Ø²': 'Ø§Ù„Ø§Ø±ØªÙƒØ§Ø²', 
            'Ø£Ø¹Ù„Ù‰': 'Ø£Ø¹Ù„Ù‰', 'Ø£Ù‚Ù„': 'Ø£Ù‚Ù„', 'Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ¯Ø§ÙˆÙ„': 'Ù‚ÙŠÙ…Ø©'
        }
        for col in df.columns:
            for k, v in mapping.items():
                if k in col: df.rename(columns={col: v}, inplace=True)
        
        df['Ø§Ù„Ø±Ù…Ø²'] = df['Ø§Ù„Ø±Ù…Ø²'].astype(str).str.strip()
        return df
    except Exception as e:
        st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")
        return None

# --- Ù…Ø­Ø±Ùƒ Ø¥Ù„ÙŠÙˆØª ÙˆØ§Ù„Ø²Ù…Ù† Ø§Ù„Ø¹Ù…ÙŠÙ‚ (Ø¨Ø¯ÙˆÙ† Ø§Ø®ØªØµØ§Ø±) ---
def deep_elliott_wave_analysis(ticker, current_p):
    try:
        # Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø³Ù†ØªÙŠÙ† Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ‚
        hist = yf.download(f"{ticker}.CA", period="2y", interval="1d", progress=False)
        if isinstance(hist.columns, pd.MultiIndex): 
            hist.columns = hist.columns.get_level_values(0)
        
        if hist.empty: return None

        # [1] ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„Ø¹Ø¸Ù…Ù‰ (Grand Cycle)
        grand_low_p = hist['Low'].min()
        grand_low_date = hist['Low'].idxmin()
        grand_high_p = hist['High'].max()
        
        # Ø­Ø³Ø§Ø¨ Ù…Ø³ØªÙ‡Ø¯Ù Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„Ø¹Ø¸Ù…Ù‰ 3 (1.618 Ù…Ù† Ø·ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¬Ø© 1)
        grand_wave_1_size = grand_high_p - grand_low_p
        major_target_3 = grand_low_p + (grand_wave_1_size * 1.618)
        major_target_5 = grand_low_p + (grand_wave_1_size * 2.618)
        
        # [2] ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ© (Sub-Waves)
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¢Ø®Ø± Ù‚Ø§Ø¹ ØªØµØ­ÙŠØ­ÙŠ (Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©)
        recent_hist = hist.tail(90) # Ø¢Ø®Ø± 3 Ø´Ù‡ÙˆØ±
        sub_low_p = recent_hist['Low'].min()
        sub_low_date = recent_hist['Low'].idxmin()
        
        # Ø­Ø³Ø§Ø¨ Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†Ø³Ø¨ ÙÙŠØ¨ÙˆÙ†Ø§ØªØ´ÙŠ
        sub_target = sub_low_p + ((current_p - sub_low_p) * 1.618) if current_p > sub_low_p else current_p * 1.15
        
        # [3] Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø²Ù…Ù†ÙŠ (Fibonacci Time Cycles)
        # Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø§Ù„Ù…ØªÙˆØ³Ø·Ø© 55 ÙŠÙˆÙ…ØŒ ÙˆØ§Ù„Ø¹Ø¸Ù…Ù‰ 144 ÙŠÙˆÙ…
        expected_sub_end = sub_low_date + timedelta(days=55)
        expected_major_end = grand_low_date + timedelta(days=144)
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©
        next_wave_start = expected_sub_end + timedelta(days=3)
        next_wave_end = next_wave_start + timedelta(days=34)

        return {
            "hist": hist,
            "grand_low_p": grand_low_p, "grand_low_date": grand_low_date.date(),
            "major_t3": major_target_3, "major_t5": major_target_5,
            "major_end_date": expected_major_end.date(),
            "sub_low_p": sub_low_p, "sub_low_date": sub_low_date.date(),
            "sub_target": sub_target, "sub_end_date": expected_sub_end.date(),
            "next_wave_start": next_wave_start.date(), "next_wave_end": next_wave_end.date()
        }
    except: return None

# --- Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙÙ†ÙŠØ© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ---
def calculate_all_indicators(df_hist):
    df = df_hist.copy()
    # MACD
    ema12 = df['Close'].ewm(span=12, adjust=False).mean()
    ema26 = df['Close'].ewm(span=26, adjust=False).mean()
    df['MACD'] = ema12 - ema26
    df['Signal'] = df['MACD'].ewm(span=9, adjust=False).mean()
    # RSI
    delta = df['Close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
    df['RSI'] = 100 - (100 / (1 + (gain/loss)))
    # Bollinger
    df['MA20'] = df['Close'].rolling(20).mean()
    df['UP'] = df['MA20'] + (df['Close'].rolling(20).std() * 2)
    df['LOW'] = df['MA20'] - (df['Close'].rolling(20).std() * 2)
    return df

# --- Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ ---
st.title("ğŸ¹ Ù†Ø¸Ø§Ù… Z88 PREDATOR - Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…Ø¤Ø³Ø³Ø§ØªÙŠ Ø§Ù„Ø´Ø§Ù…Ù„")
st.markdown("---")

uploaded_file = st.sidebar.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù Prices, support & Resistance", type=["csv", "xlsx"])

if uploaded_file:
    df_main = load_and_fix_data(uploaded_file)
    if df_main is not None:
        st.sidebar.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ù€ 13 Ø¨Ù†Ø¬Ø§Ø­")
        
        # Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù†Ø³Ø¯Ù„Ø© Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø³Ù‡Ù…
        sel_ticker = st.selectbox("ğŸ” Ø§Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø³Ù‡Ù… (Z1, Z6, Z7, Z88):", df_main['Ø§Ù„Ø±Ù…Ø²'].unique())
        row = df_main[df_main['Ø§Ù„Ø±Ù…Ø²'] == sel_ticker].iloc[0]
        p_now = row['Ø¥ØºÙ„Ø§Ù‚']
        
        st.header(f"ğŸ›ï¸ Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… Ø³Ù‡Ù…: {row['Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒÙ‡']} ({sel_ticker})")

        # ØªØ´ØºÙŠÙ„ Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„
        with st.spinner('Ø¬Ø§Ø±ÙŠ ØªØ´ØºÙŠÙ„ ØªØ­Ù„ÙŠÙ„ Ø¥Ù„ÙŠÙˆØª ÙˆØ§Ù„Ø²Ù…Ù† ÙˆØ§Ù„Ù…ÙŠÙƒØ±...'):
            wave_data = deep_elliott_wave_analysis(sel_ticker, p_now)

        if wave_data:
            # --- ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø­Ø³Ø¨ Ø·Ù„Ø¨Ùƒ (ØªØ­Ù„ÙŠÙ„ ØªÙØµÙŠÙ„ÙŠ Ù…Ù…Ù„) ---
            
            # 1. Ù‚Ø³Ù… Ù…ÙˆØ¬Ø§Øª Ø¥Ù„ÙŠÙˆØª (Ø§Ù„ØªØ´Ø±ÙŠØ­ Ø§Ù„ÙƒØ§Ù…Ù„)
            st.divider()
            st.subheader("ğŸŒŠ 1. ØªØ´Ø±ÙŠØ­ Ù…ÙˆØ¬Ø§Øª Ø¥Ù„ÙŠÙˆØª (Ø§Ù„Ø¹Ø¸Ù…Ù‰ ÙˆØ§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©)")
            
            c1, c2 = st.columns(2)
            with c1:
                st.info("ğŸ›ï¸ Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„Ø¹Ø¸Ù…Ù‰ (Grand Cycle)")
                st.write(f"ğŸ”¹ Ø¨Ø¯Ø£Øª Ù…Ù† Ø³Ø¹Ø±: **{wave_data['grand_low_p']:.2f}**")
                st.write(f"ğŸ”¹ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø§Ù†Ø·Ù„Ø§Ù‚: **{wave_data['grand_low_date']}**")
                st.success(f"ğŸ¯ Ù…Ø³ØªÙ‡Ø¯Ù Ù…ÙˆØ¬Ø© 3 Ø§Ù„Ø¹Ø¸Ù…Ù‰: **{wave_data['major_t3']:.2f}**")
                st.write(f"ğŸ Ù…Ø³ØªÙ‡Ø¯Ù Ù…ÙˆØ¬Ø© 5 Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: **{wave_data['major_t5']:.2f}**")
                st.write(f"ğŸ“… Ù…ÙˆØ¹Ø¯ Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„Ø¯ÙˆØ±Ø© Ø§Ù„Ø¹Ø¸Ù…Ù‰: **{wave_data['major_end_date']}**")
            
            with c2:
                st.warning("ğŸ“ Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ© (Sub-Wave)")
                st.write(f"ğŸ”¸ Ø§Ù„Ø³Ù‡Ù… Ø­Ø§Ù„ÙŠØ§Ù‹ ÙÙŠ: **Ù…ÙˆØ¬Ø© Ø¯Ø§Ø®Ù„ÙŠØ© ØµØ§Ø¹Ø¯Ø©**")
                st.write(f"ğŸ”¸ Ø¨Ø¯Ø£Øª Ù…Ù† Ù‚Ø§Ø¹ ÙØ±Ø¹ÙŠ Ø¹Ù†Ø¯: **{wave_data['sub_low_p']:.2f}**")
                st.write(f"ğŸ”¸ ØªØ§Ø±ÙŠØ® Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©: **{wave_data['sub_low_date']}**")
                st.success(f"ğŸ¯ Ù…Ø³ØªÙ‡Ø¯Ù Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠ: **{wave_data['sub_target']:.2f}**")
                st.error(f"â³ ØªÙ†ØªÙ‡ÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙˆØ¬Ø© ÙÙŠ: **{wave_data['sub_end_date']}**")
            
            st.info(f"â­ï¸ **Ø§Ù„Ù…ÙˆØ¬Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©:** ØªØµØ­ÙŠØ­ ÙØ±Ø¹ÙŠ ÙŠØ¨Ø¯Ø£ ÙŠÙˆÙ… **{wave_data['next_wave_start']}** ÙˆÙŠÙ†ØªÙ‡ÙŠ ÙŠÙˆÙ… **{wave_data['next_wave_end']}**")

            # 2. Ù‚Ø³Ù… Ø§Ù„Ù‚Ù†Ø§Øµ (Ù†Ù‚Ø§Ø· Ø§Ù„ØªÙ†ÙÙŠØ°)
            st.divider()
            st.subheader("ğŸ¯ 2. Ø±Ø§Ø¯Ø§Ø± Ø§Ù„Ù‚Ù†Ø§Øµ (Ø§Ù„Ø¯Ø®ÙˆÙ„ ÙˆØ§Ù„Ø®Ø±ÙˆØ¬)")
            q1, q2, q3 = st.columns(3)
            q1.metric("Ø£ÙØ¶Ù„ Ø³Ø¹Ø± Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø¢Ù†", f"{((wave_data['sub_low_p'] + p_now)/2):.2f}")
            q2.metric("Ø¯Ø¹Ù… Ø§Ù„Ø£ÙˆØ±Ø¯Ø± Ø¨Ù„ÙˆÙƒ (Buy)", f"{wave_data['hist']['Low'].tail(20).min():.2f}")
            q3.metric("Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø£ÙˆØ±Ø¯Ø± Ø¨Ù„ÙˆÙƒ (Sell)", f"{wave_data['hist']['High'].tail(20).max():.2f}")

            # 3. Ù‚Ø³Ù… Ø²ÙˆØ§ÙŠØ§ Ø¬Ø§Ù†
            st.divider()
            st.subheader("ğŸ“ 3. ØªØ­Ù„ÙŠÙ„ Ø²ÙˆØ§ÙŠØ§ Ø¬Ø§Ù† Ø§Ù„Ø³Ø¹Ø±ÙŠØ©")
            root = np.sqrt(p_now)
            j1, j2, j3 = st.columns(3)
            j1.write(f"ğŸ“ Ø²Ø§ÙˆÙŠØ© 90: **{(root + 0.5)**2:.2f}**")
            j2.write(f"ğŸ“ Ø²Ø§ÙˆÙŠØ© 180 (Ù‚Ù„Ø¨ Ø§Ù„Ø§ØªØ¬Ø§Ù‡): **{(root + 1)**2:.2f}**")
            j3.write(f"ğŸ“ Ø²Ø§ÙˆÙŠØ© 360 (Ø¯ÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø©): **{(root + 2)**2:.2f}**")

            # 4. Ù‚Ø³Ù… Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ÙˆØ§Ù„Ø³ÙƒÙˆÙŠØ²
            st.divider()
            st.subheader("ğŸ“ˆ 4. Ù†Ø¨Ø¶ Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª ÙˆØ§Ù„Ø³ÙƒÙˆÙŠØ²")
            tech_df = calculate_all_indicators(wave_data['hist'])
            m1, m2, m3 = st.columns(3)
            m1.metric("RSI (14)", f"{tech_df['RSI'].iloc[-1]:.2f}")
            m2.write(f"**Ø­Ø§Ù„Ø© MACD:** {'Ø¥ÙŠØ¬Ø§Ø¨ÙŠ ØµØ§Ø¹Ø¯ âœ…' if tech_df['MACD'].iloc[-1] > tech_df['Signal'].iloc[-1] else 'Ø³Ù„Ø¨ÙŠ Ù‡Ø§Ø¨Ø· âŒ'}")
            m3.write(f"**Ø§Ù„Ø³ÙƒÙˆÙŠØ² Ù…ÙˆÙ…Ù†ØªÙ…:** {'Ø§Ù†ÙØ¬Ø§Ø± ÙˆØ´ÙŠÙƒ ğŸš€' if row['Ø§Ù„Ø³ÙŠÙˆÙ„Ø©'] > 60 else 'ØªØ¬Ù…ÙŠØ¹ Ù‡Ø§Ø¯Ø¦ ğŸ˜´'}")

            # 5. Ø§Ù„Ø´Ø§Ø±Øª Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ
            st.divider()
            st.subheader("ğŸ“Š 5. Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø³Ø¹Ø±ÙŠ ÙˆØ§Ù„Ø²Ù…Ù†ÙŠ Ø§Ù„Ù…Ø±Ø³ÙˆÙ…")
            fig = go.Figure(data=[go.Candlestick(x=wave_data['hist'].index, open=wave_data['hist']['Open'], 
                                                 high=wave_data['hist']['High'], low=wave_data['hist']['Low'], 
                                                 close=wave_data['hist']['Close'], name='Ø§Ù„Ø³Ø¹Ø±')])
            fig.add_hline(y=wave_data['sub_target'], line_dash="dash", line_color="orange", annotation_text="Ù‡Ø¯Ù Ø¯Ø§Ø®Ù„ÙŠØ©")
            fig.add_hline(y=wave_data['major_t3'], line_dash="dot", line_color="green", annotation_text="Ù‡Ø¯Ù Ø¹Ø¸Ù…Ù‰")
            fig.update_layout(template="plotly_dark", height=600)
            st.plotly_chart(fig, use_container_width=True)

            # 6. Ù‚Ø³Ù… Ø§Ù„Ø³ÙŠÙƒÙˆÙ„ÙˆØ¬ÙŠØ© ÙˆØ§Ù„Ø­ÙŠØªØ§Ù†
            st.divider()
            st.subheader("ğŸ³ 6. Ø³ÙŠÙƒÙˆÙ„ÙˆØ¬ÙŠØ© Ø§Ù„Ø­ÙŠØªØ§Ù† ÙˆØ§Ù„Ù…ÙŠÙƒØ±")
            st.info(f"Ø­Ø¬Ù… ØªØ¯ÙÙ‚ Ø§Ù„Ø³ÙŠÙˆÙ„Ø©: **{row['Ø§Ù„Ø³ÙŠÙˆÙ„Ø©']}%**")
            st.warning(f"âš ï¸ ÙˆÙ‚Ù Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: **{p_now * 0.94:.2f}**")
            
            # 7. ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±
            st.divider()
            csv_ticker = wave_data['hist'].to_csv(index=True, encoding='utf-8-sig').encode('utf-8-sig')
            st.download_button(f"ğŸ“¥ ØªØ­Ù…ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± {sel_ticker} Ø§Ù„ØªÙØµÙŠÙ„ÙŠ", csv_ticker, f"{sel_ticker}_Analysis.csv")

        # Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù… ÙÙŠ Ø§Ù„Ø£Ø³ÙÙ„
        st.divider()
        st.subheader("ğŸ“‹ Ù…Ù„Ø®Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø¹Ø§Ù…")
        st.dataframe(df_main[['Ø§Ù„Ø±Ù…Ø²', 'Ø§Ø³Ù… Ø§Ù„Ø´Ø±ÙƒÙ‡', 'Ø¥ØºÙ„Ø§Ù‚', 'Ø§Ù„Ø³ÙŠÙˆÙ„Ø©']])
        st.download_button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø¯Ø§ØªØ§ Ø§Ù„Ø³ÙˆÙ‚ ÙƒØ§Ù…Ù„Ø© (Ø¹Ø±Ø¨ÙŠ)", df_main.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig'), "Market_Z88.csv")

else:
    st.info("ğŸ‘‹ Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø§ÙƒÙŠÙ†Ø© Ø§Ù„Ø¹Ù…Ù„Ø§Ù‚Ø©.")
